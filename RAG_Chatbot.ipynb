{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vidhyampp/AI-Travel-Planner/blob/main/RAG_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Fetching the Data from the Database and giving it to the llm\n",
        "---In this experiment I tried to create a RAG pipeline for the chatbot which answers the questions on the dsl lab\n",
        "2. ChromaDB is used as the vector database\n",
        "---OpenAI as LLM\n",
        "3. Setup OpenAI API Key and import it to the collab\n",
        "4. Explored the LangChain > went to how to load web pages\n",
        "5. Used web base loader from lang chain community, can give list of websites or one website , print the docs to see it scrapped or not\n",
        "6. Split the entire data into splits > Text splitters in langchain- chunk_size and chunk_over ,(if the texts are available in two chunks, overlapp allows it to understand that its the continuation )- used RecursiveCharacterTextSplitter function here\n",
        "7. Print the splits to see the data splitted and overlapped\n",
        "8. Change the splits into vectors(text into numbers(vectors). Using openAIEmbeddings to convert text into vectors\n",
        "9. Print the collection and the id's of the collection\n",
        "10. Create the RAG Pipeline"
      ],
      "metadata": {
        "id": "UI9E4aWcmLvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community langchainhub chromadb langchain langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Bp8QGO55xqSM",
        "outputId": "517ec68e-f576-4917-ba46-c9adb70662c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.78 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.78)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain_community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.33)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Collecting packaging<25,>=23.2 (from langchainhub)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.10)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.37.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.19.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.35.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.78->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
            "Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=2eab4b9aef943c6941f98d536565c6ba8812c7af2d62f1c8da60f942529fff3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pybase64, packaging, opentelemetry-proto, mypy-extensions, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, typing-inspect, types-requests, requests, opentelemetry-exporter-otlp-proto-common, marshmallow, coloredlogs, posthog, onnxruntime, langchainhub, dataclasses-json, kubernetes, opentelemetry-exporter-otlp-proto-grpc, langchain-openai, chromadb, langchain_community\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.1.1 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 langchain-openai-0.3.35 langchain_community-0.3.31 langchainhub-0.1.21 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 onnxruntime-1.23.1 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 packaging-24.2 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 requests-2.32.5 types-requests-2.32.4.20250913 typing-inspect-0.9.0 urllib3-2.3.0 uvloop-0.21.0 watchfiles-1.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "packaging"
                ]
              },
              "id": "a33e08aea6c9480aafe479ab898d3957"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CuOOw9OfmGH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Install to an isolated target dir\n",
        "%pip install -q -t /content/libs \\\n",
        "  \"requests==2.32.5\" \"packaging==24.2\" \"urllib3==2.3.0\" \\\n",
        "  \"langchain-community==0.3.31\" \"langchainhub==0.1.21\"\n",
        "\n",
        "# 2) Prepend that folder to Python's import path\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/libs\")\n",
        "\n",
        "# 3) Verify\n",
        "import requests, packaging\n",
        "print(\"requests:\", requests.__version__)\n",
        "print(\"packaging:\", packaging.__version__)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSB1PEoHVT3r",
        "outputId": "190279e4-ff88-411b-d377-c3f339b28db7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "gradio 5.49.0 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.2 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
            "google-adk 1.14.1 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain-0.3.27.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/sniffio-1.3.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain_core already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langsmith-0.4.35.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/urllib3-2.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/annotated_types already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/anyio-4.11.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/jsonpatch-1.33.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/mypy_extensions-1.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/requests_toolbelt-1.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/httpx_sse-0.4.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/marshmallow-3.26.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain_community-0.3.31.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain_core-0.3.79.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/jsonpatch.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pydantic_core-2.41.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchainhub already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/orjson-3.11.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain_text_splitters already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/typing_inspect-0.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/idna already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/charset_normalizer-3.4.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/aiosignal already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/aiosignal-1.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/anyio already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/aiohttp already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/python_dotenv-1.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/propcache-0.4.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/tenacity-9.1.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/httpcore already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/jsonpointer.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/typing_inspection already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/aiohappyeyeballs-2.6.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/attrs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/httpx-0.28.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/numpy-2.3.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/attrs-25.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/greenlet already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/frozenlist already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/sqlalchemy-2.0.44.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/yarl-1.22.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/sqlalchemy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchainhub-0.1.21.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/packaging-24.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/attr already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/idna-3.11.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/sniffio already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pydantic-2.12.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/h11 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/jsonpointer-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/yarl already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/tenacity already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/marshmallow already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain_community already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pydantic_core already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/certifi-2025.10.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/aiohappyeyeballs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/dataclasses_json-0.6.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/zstandard-0.25.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langsmith already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/greenlet-3.2.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/aiohttp-3.13.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/types_requests-2.32.4.20250913.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/h11-0.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/_yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/multidict-6.7.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pydantic_settings already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/dotenv already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/propcache already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/orjson already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/typing_inspection-0.4.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pydantic already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/requests-2.32.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/typing_inspect.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pydantic_settings-2.11.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/mypy_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain_text_splitters-0.3.11.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/requests_toolbelt already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/requests-stubs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/multidict already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/annotated_types-0.7.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/zstandard already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/httpx_sse already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/dataclasses_json already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/requests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/httpx already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/frozenlist-1.8.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pyyaml-6.0.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/httpcore-1.0.9.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/include already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0mrequests: 2.32.5\n",
            "packaging: 24.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "LIB_DIR = \"/content/libs\"\n",
        "if LIB_DIR not in sys.path:\n",
        "    sys.path.insert(0, LIB_DIR)\n",
        "print(sys.path[0])  # should be /content/libs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWKkQRaa3vzG",
        "outputId": "5d45869f-f49f-4a4c-c9c9-bb2792e2456b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/libs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q -t /content/libs \\\n",
        "  langchain-community==0.3.31 langchainhub==0.1.21 \\\n",
        "  chromadb==1.1.1 langchain-openai==0.3.35 \\\n",
        "  urllib3==2.3.0 requests==2.32.5 packaging==24.2\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VkxHglup34vX",
        "outputId": "44bf04ef-a468-4ff5-e852-048ad29bab37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.41.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n",
            "bigframes 2.24.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "gradio 5.49.0 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.2 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.1 which is incompatible.\n",
            "google-adk 1.14.1 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.32.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/httptools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/backoff-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/watchfiles-1.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/jsonschema already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/tqdm already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain_openai already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pygments already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pyasn1_modules-0.4.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/rpds already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/importlib_resources-6.5.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain-0.3.27.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/sniffio-1.3.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/referencing-0.37.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/shellingham-1.5.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain_core already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/tiktoken-0.12.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/google already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/tokenizers-0.22.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langsmith-0.4.35.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/urllib3-2.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/annotated_types already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/zipp-3.23.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/overrides already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/backoff already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/anyio-4.11.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/referencing already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/onnxruntime already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/jsonpatch-1.33.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/mypy_extensions-1.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/opentelemetry already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/requests_toolbelt-1.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/httpx_sse-0.4.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/build already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/isympy.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/marshmallow-3.26.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/humanfriendly already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/schemas already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/hf_xet-1.1.10.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain_community-0.3.31.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain_core-0.3.79.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/requests_oauthlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/jsonpatch.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pydantic_core-2.41.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pypika already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/openai already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/tqdm-4.67.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchainhub already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/sympy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/orjson-3.11.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/humanfriendly-10.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain_text_splitters already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/typing_inspect-0.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/idna already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/charset_normalizer-3.4.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/uvicorn-0.37.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/aiosignal already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/aiosignal-1.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/websockets-15.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/anyio already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/distro-1.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/aiohttp already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pybase64 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/python_dotenv-1.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/propcache-0.4.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pybase64-1.4.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/jsonschema_specifications already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/websockets already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/importlib_resources already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/tenacity-9.1.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/httpcore already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/filelock-3.20.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/jsonpointer.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/typing_inspection already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/aiohappyeyeballs-2.6.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/uvloop already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/attrs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/httpx-0.28.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/numpy-2.3.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/build-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/attrs-25.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pypika-0.48.9.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/tiktoken_ext already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/opentelemetry_api-1.37.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/protobuf-6.32.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/mmh3.cpython-312-x86_64-linux-gnu.so already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/rsa-4.9.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/greenlet already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/tiktoken already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/chromadb already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/frozenlist already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/opentelemetry_sdk-1.37.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/sqlalchemy-2.0.44.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/coloredlogs.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/yarl-1.22.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/jsonschema-4.25.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/rsa already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/opentelemetry_semantic_conventions-0.58b0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/sqlalchemy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/opentelemetry_exporter_otlp_proto_common-1.37.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchainhub-0.1.21.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/packaging-24.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/attr already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/chromadb-1.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/typer-0.19.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/mmh3-5.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/mdurl-0.1.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/jsonschema_specifications-2025.9.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/jiter already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/cachetools-6.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/idna-3.11.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/sniffio already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pydantic-2.12.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/h11 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/six-1.17.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/jsonpointer-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/huggingface_hub-0.35.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/grpc already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/yarl already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/tenacity already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/overrides-7.7.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/marshmallow already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/oauthlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/dateutil already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/durationpy-0.10.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/click already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/flatbuffers-25.9.23.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/coloredlogs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain_community already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/websocket_client-1.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/jiter-0.11.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pydantic_core already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pygments-2.19.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/certifi-2025.10.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain_openai-0.3.35.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/rich already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pyasn1_modules already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/hf_xet already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/aiohappyeyeballs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/huggingface_hub already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/dataclasses_json-0.6.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/bcrypt already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/rpds_py-0.27.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/zstandard-0.25.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langsmith already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/opentelemetry_exporter_otlp_proto_grpc-1.37.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/greenlet-3.2.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/googleapis_common_protos-1.70.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/tokenizers already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/mmh3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/uvloop-0.21.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/openai-2.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/aiohttp-3.13.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pyproject_hooks already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/regex already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/types_requests-2.32.4.20250913.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/h11-0.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/_yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/google_auth-2.41.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/importlib_metadata already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/rich-14.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pyasn1-0.6.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/durationpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/kubernetes already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/multidict-6.7.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pydantic_settings already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/watchfiles already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/chromadb_rust_bindings already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/posthog-5.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/dotenv already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/propcache already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/orjson already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/typer already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/typing_inspection-0.4.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/markdown_it_py-4.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/regex-2025.9.18.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pydantic already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/requests-2.32.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/distro already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/typing_inspect.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pyproject_hooks-1.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/filelock already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/grpcio-1.75.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/requests_oauthlib-2.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/oauthlib-3.3.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pydantic_settings-2.11.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/mypy_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/uvicorn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/langchain_text_splitters-0.3.11.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/zipp already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/requests_toolbelt already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/posthog already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/fsspec already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/bcrypt-5.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/requests-stubs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/multidict already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/annotated_types-0.7.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/opentelemetry_proto-1.37.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/zstandard already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/httpx_sse already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/python_dateutil-2.9.0.post0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/coloredlogs-15.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/mdurl already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/kubernetes-34.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/dataclasses_json already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/requests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/markdown_it already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/httpx already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/websocket already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pyasn1 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/importlib_metadata-8.7.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/frozenlist-1.8.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/cachetools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/shellingham already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/mpmath already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/httptools-0.7.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/flatbuffers already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/pyyaml-6.0.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/httpcore-1.0.9.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/onnxruntime-1.23.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/click-8.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/include already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/libs/share already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4174208937.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install -q -t /content/libs    langchain-community==0.3.31 langchainhub==0.1.21    chromadb==1.1.1 langchain-openai==0.3.35    urllib3==2.3.0 requests==2.32.5 packaging==24.2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_installation_commands.py\u001b[0m in \u001b[0;36m_pip_magic\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# Colab is set up such that pip does the right thing, and pip install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;31m# will properly trigger the pip install warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, packaging, subprocess, sys\n",
        "print(\"requests:\", requests.__version__)\n",
        "print(\"packaging:\", packaging.__version__)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"check\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4ONtKdsVYCY",
        "outputId": "5a37fd21-0622-4e02-eb22-fab457d0f782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requests: 2.32.5\n",
            "packaging: 24.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['/usr/bin/python3', '-m', 'pip', 'check'], returncode=1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, packaging, inspect\n",
        "print(\"requests:\", requests.__version__)\n",
        "print(\"packaging:\", packaging.__version__)\n",
        "print(\"requests file:\", inspect.getfile(requests))  # should point into /content/libs/...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YEMN-l-4cum",
        "outputId": "d3c44ea4-f396-43d0-bc09-0da28130d129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requests: 2.32.5\n",
            "packaging: 24.2\n",
            "requests file: /content/libs/requests/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('reserch')"
      ],
      "metadata": {
        "id": "Oy6Th5l_yRcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(web_paths=[\"https://www.ece.iastate.edu/~mai/lab/dsl.html\"])\n",
        "\n",
        "docs = loader.load()\n",
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UzoNGeYy0jL",
        "outputId": "39cc52a5-60c7-426a-d042-77abc580bc4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'title': 'Mai Zheng @Iowa State', 'language': 'No language found.'}, page_content=\"\\n\\n\\n\\nMai Zheng @Iowa State\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMai Zheng\\n               (Mike)\\n\\nAssociate Professor\\nDept.\\n                of Electrical and Computer Engineering\\n\\nData Storage Lab (DSL)\\n\\nCenter for Cybersecurity Innovation\\n                & Outreach (CyIO)\\n\\nCenter for Wireless, Communities and\\n                Innovation (WiCI)\\n\\n \\n Office: 349 Durham Hall\\n              Phone: (515)\\n                294-6285 \\n              Email: mai AT iastate DOT edu \\nwww.ece.iastate.edu/~mai\\n\\n\\n\\n I'm interested in all\\n                  things data storage (e.g., file systems,\\n              non-volatile memories, key-value stores, data-intensive computing,\\n              data-centric infrastructures). I'm leading the Data\\n                  Storage Lab where we play with the latest storage\\n              technologies and strive to advance the integrity, security,\\n              scalability, usability etc for data, for people, or just for fun.\\n            \\n\\n\\n\\n\\n\\n\\nData Storage Lab\\nOur research are\\n              motivated by real problems of mission-critical systems that jeopardize\\n              data, e.g.: \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n                              Crash, \\n                              Corruption, & Bug\\n                          across system layers\\n                          ==> [SSD: TOCS'16/FAST'13 |\\n                       \\n                        FS: FAST'23,\\n                        FAST'18 |\\n                          OS: TOS'23 |\\n                        DB: OSDI'14]\\n                         Data\\n                              Lost & Service\\n                              Disruption\\n                          @HPC/Data\\n                            centers at scale\\n\\n                        ==> [HotStorage'24,\\n                        TOS'22/ICS'18,\\n                          IPDPS'23,\\n                        ATC'19]\\n                        Data\\n                              Provenance, Observability,\\n                          & Scalability\\n                          challenges\\n                        ==> [TPDS'24/HPDC'22,\\n                        ASPLOS'23,\\n                          ARA Platform]\\n                      \\n\\n\\n\\n\\n\\nWe build\\n              systems/tools to attack such problems and open source our \\n                research prototypes/datasets. \\n\\n\\n\\n\\n Current Members \\n\\n\\n\\nFaculty: Mai\\n                        Zheng \\nStudents:\\n                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWei Xu\\nChao Shi\\nRoop Kiran\\nAhmed Dajani\\nVarun Girimaji\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nVidhya Mannathu Parambil \\nJoshua John\\n Aaron Trelstad  \\n Zeren Yang\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Selected Projects\\n\\n\\n\\nLarge-Scale\\n                    High-Performance Storage Systems \\n\\n\\n\\n \\n\\n\\n\\n Large-scale distributed storage\\n                            systems   are critical infrastructures typically deployed in data centers and high-perfomrance computing (HPC) centers to \\n                            empower data-intensive computations and \\n                            data-driven discoveries (e.g., AI/ML applications). Unfortunately,\\n                             due to the complexity and scale, even state-of-the-art systems may experience correctness\\n                            and/or performance issues. \\n                            We are building frameworks to improve data storage at scale\\n                             for robust and high-performant data-driven discoveries.\\nRelevant Papers:\\n                            [IPDPS'25\\n                            | CN'25\\n                            | HotStorage'24\\n                            | ASPLOS'23\\n                            | IPDPS'23a\\n                            | IPDPS'23b\\n                            | TOS'22\\n                             | HPDC'22\\n                            | HotStorage'21\\n                            (video)\\n                            | PDSW'20\\n                            (slides)\\n                            | \\n                                  USENIX ATC'19 (slides)\\n                            | MSST'19\\n                                  | PDSW'18\\n                                (slides)\\n                            | ICS'18\\n                            (slides)\\n                            \\n                            | PDSW'16\\n                            (slides)]\\n                            \\nOpen Source\\n                                Artifacts: [PFault | ARA Platform]\\n                          \\n\\n                                Main Sponsors: \\n                                [NSF \\n                                | Samsung\\n                                | NIFA \\n                                | US Ignite]\\n                              \\n\\n\\n\\n\\n\\n\\n\\n Single-Machine Storage\\n                       \\n\\n\\n\\n \\n\\n\\n\\nLocal storage systems running on a single machine serve as the\\n                                cornerstone of many large-scale systems and applications. Unfortunately, despite decades of\\n                                evolution and various protections, the classic local storage\\n                                systems may still run into issues in practice\\n                                (e.g., data corruptions, metadata\\n                                inconsistencies). What's worse, the same issues\\n                                that occur to lcoal storage systems may also affect their\\n                                maintenance/recovery utilities and/or\\n                                other applications using them, leading to\\n                                cascading problems. We are investigating the fundamental\\n                                problems and developing mitigation solutions.\\nRelevant Papers:\\n                                [TOCS'25\\n                                  | FAST'23\\n                                | HotStorage'22\\n                                (slides)\\n                                | FAST'22-WiP\\n                                (video)\\n                                | TOS'18\\n                                | FAST'18\\n                                (slides)\\n                                | HotStorage'17\\n                                (slides)\\n                                | FAST'17-WiP]\\n                              \\n\\nOpen Source\\n                                    Artifacts: [ConfD | RFSCK]\\n                              \\n Main Sponsors: \\n                                [NSF \\n                                | Western Digital]\\n                              \\n\\n\\n\\n\\n\\n\\n\\n\\n  Cross-Layer\\n                        Issues on Data Path \\n\\n\\n\\n \\n\\n\\n\\nThe storage  stack contains a deep data I/O path involving complicated layers (e.g., solid-state drives (SSD), persistent memories (PM), device drivers, local and parallel\\n                                file systems, databases, blockchain storage with cloud backends). Besides\\n                                latent issues in individual layers, many\\n                                desired properties may be violated due to  cross-layer dependencies, hurting the\\n                                end-to-end gurantees and data integrity. We take a holistic\\n                                view to investigate such daunting challenges across system layers. \\nRelevant Papers:\\n                                [IPDPS'25\\n                                 | TOS'23\\n                                | FAST'23\\n                                | Dagstuhl'22\\n                                | TOS'22\\n                                | NVMW'23\\n                                | TC'22\\n                                | SYSTOR'21\\n                                (video)\\n                                | FAST'20-WiP\\n                                | \\n                                  ATC'19\\n                                | TOS'18\\n                                | TOCS'16\\n                                | OSDI'14\\n                                (slides)\\n                                | FAST'13\\n                                (slides)\\n                                ]\\nOpen Source\\n                                    Artifacts: [BugBenchk \\n                                | ConfD | PFault]\\n Main Sponsors: \\n                                [NSF \\n                                | Western Digital]\\n                              \\n\\n\\n\\n\\n\\n\\n\\n\\n  Data Provenance &\\n                        Observability  \\n\\n\\n\\n \\n\\n\\n\\n Understanding the origin and quality of data\\n                                (e.g., the root cause of an anomaly, the\\n                                reproducibility of the best result) becomes more\\n                                and more challenging due to the ever-increasing\\n                                data volume and system complexity. Data\\n                                  provenance, or data lineage, describes the\\n                                life cycle of data, which is essential to\\n                                address the challenge. We are building\\n                                frameworks to capture rich metadata and generate\\n                                provenance to ensure the observability,\\n                                reproducibility, explainability, auditability,\\n                                trustworthiness, etc of systems and data.\\nRelevant Papers:\\n                                [TPDS'24\\n                                | HPDC'22\\n                                | NAS'22\\n                                | FAST'22-WiP\\n                                | DOE-ASRC-Data'22\\n                                | TBench'21\\n                                (video)\\n                                | HotStorage'20\\n                                (slides)\\n                                ]\\nOpen Source Artifacts: \\n                                [PROV-IO\\n                                | BugBenchk]\\n                              \\nMain Sponsors: \\n                                [NSF \\n                                | LBNL \\n                                | Samsung]\\n                              \\n\\n\\n\\n\\n\\n\\n\\n Data Infrastructure for\\n                        Rural America \\n\\n\\n\\n \\n\\n\\n\\nARA is a data infrastructure for\\n                                advanced wireless research being deployed across\\n                                the ISU campus, City of Ames, and surrounding\\n                                research and producer farms as well as rural\\n                                communities in central Iowa, spanning a rural\\n                                area with diameter over 60km. It serves as a\\n                                wireless living lab for smart and connected\\n                                rural communities and rich experimental data,\\n                                enabling the research and development of\\n                                rural-focused wireless technologies that provide\\n                                affordable, high-capacity connectivity to rural\\n                                communities and industries such as agriculture.\\n                              \\nRelevant Papers:\\n                                [ CN'25\\n                                | MobiCom'23\\n                                | WiNTECH'22\\n                                | \\n                                  WiNTECH'21] \\n\\n                                Open Source\\n                                Artifacts: [ARA Platform]\\n                              \\n\\n                                Main Sponsors: \\n                                [NSF \\n                                | NIFA \\n                                | US Ignite\\n                                | PAWR Industry Consortium]\\n                              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Selected Outreach Activities \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Full\\n                    Publication List  \\n\\n Alumni\\n \\n\\n Acknowledgements\\n                       \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n\\n\\n Homepage\\n\\n                  CV \\n Data\\n                  Storage Lab\\n\\n                  Publications\\n\\n                  Students\\n\\n                  Teaching\\n\\n                  Service \\n\\n                  Ack. \\n\\n\\n\\n  \\n \\n\\n \\n\\n\\n\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "hh4mArWg0_cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(splits[0])\n",
        "print(splits[1])\n",
        "print(splits[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SM7XPdZ6Zfk",
        "outputId": "c09f3eb4-e827-49c0-9909-7e0df701f452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Mai Zheng @Iowa State\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Mai Zheng\n",
            "               (Mike)\n",
            "\n",
            "Associate Professor\n",
            "Dept.\n",
            "                of Electrical and Computer Engineering\n",
            "\n",
            "Data Storage Lab (DSL)\n",
            "\n",
            "Center for Cybersecurity Innovation\n",
            "                & Outreach (CyIO)\n",
            "\n",
            "Center for Wireless, Communities and\n",
            "                Innovation (WiCI)\n",
            "\n",
            " \n",
            " Office: 349 Durham Hall\n",
            "              Phone: (515)\n",
            "                294-6285 \n",
            "              Email: mai AT iastate DOT edu \n",
            "www.ece.iastate.edu/~mai\n",
            "\n",
            "\n",
            "\n",
            " I'm interested in all\n",
            "                  things data storage (e.g., file systems,\n",
            "              non-volatile memories, key-value stores, data-intensive computing,\n",
            "              data-centric infrastructures). I'm leading the Data\n",
            "                  Storage Lab where we play with the latest storage\n",
            "              technologies and strive to advance the integrity, security,\n",
            "              scalability, usability etc for data, for people, or just for fun.' metadata={'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'title': 'Mai Zheng @Iowa State', 'language': 'No language found.'}\n",
            "page_content='Data Storage Lab\n",
            "Our research are\n",
            "              motivated by real problems of mission-critical systems that jeopardize\n",
            "              data, e.g.: \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                              Crash, \n",
            "                              Corruption, & Bug\n",
            "                          across system layers\n",
            "                          ==> [SSD: TOCS'16/FAST'13 |\n",
            "                       \n",
            "                        FS: FAST'23,\n",
            "                        FAST'18 |\n",
            "                          OS: TOS'23 |\n",
            "                        DB: OSDI'14]\n",
            "                         Data\n",
            "                              Lost & Service\n",
            "                              Disruption\n",
            "                          @HPC/Data\n",
            "                            centers at scale' metadata={'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'title': 'Mai Zheng @Iowa State', 'language': 'No language found.'}\n",
            "page_content='==> [HotStorage'24,\n",
            "                        TOS'22/ICS'18,\n",
            "                          IPDPS'23,\n",
            "                        ATC'19]\n",
            "                        Data\n",
            "                              Provenance, Observability,\n",
            "                          & Scalability\n",
            "                          challenges\n",
            "                        ==> [TPDS'24/HPDC'22,\n",
            "                        ASPLOS'23,\n",
            "                          ARA Platform]\n",
            "                      \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "We build\n",
            "              systems/tools to attack such problems and open source our \n",
            "                research prototypes/datasets. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Current Members \n",
            "\n",
            "\n",
            "\n",
            "Faculty: Mai\n",
            "                        Zheng \n",
            "Students:\n",
            "                      \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Wei Xu\n",
            "Chao Shi\n",
            "Roop Kiran\n",
            "Ahmed Dajani\n",
            "Varun Girimaji\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Vidhya Mannathu Parambil \n",
            "Joshua John\n",
            " Aaron Trelstad  \n",
            " Zeren Yang\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Selected Projects\n",
            "\n",
            "\n",
            "\n",
            "Large-Scale\n",
            "                    High-Performance Storage Systems' metadata={'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'title': 'Mai Zheng @Iowa State', 'language': 'No language found.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(splits))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XESRbGp87BWX",
        "outputId": "dedfcd41-7909-4b1a-c3c1-9baa2dfb67e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "5taW_LOJ73OQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef75074d-0a4f-4e77-e37d-0f6fbbf75ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-52169040.py:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorstore._collection.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdu6rOsK8sXX",
        "outputId": "2472fcbc-6691-41df-88df-2fa0844d4bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorstore._collection.get())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-CE8VHQ8w3o",
        "outputId": "b7c5a885-42f6-4615-ad92-829392784c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': ['38244db0-385e-4fde-bfb7-f8c29314427b', 'f38503fc-d438-4fd9-b5f1-abed96049c83', '13ac6a63-1a70-46bc-9333-e278b66b9040', '8699b86b-22bb-4f4c-86b9-09fe9d45b41d', 'a3101e34-78e8-47e0-a5b2-ff5da37c67af', '0f8f44c9-66b2-488f-85fa-65b3a149fc61', '5b75c773-2d95-4480-b0a4-693271906eb6', '3ba204d4-129e-43f1-981c-2ac97da23aa0', 'e120c339-e3fc-42be-9817-581ee2439bd9', '2f8ee885-0c88-46ed-9bea-14c77641f7eb', 'b09413a3-e50f-4ad9-9c2d-a1e22822ac13', 'c4ea6dd9-120d-4a63-9ebc-ac354857dabe', '932af4b1-8136-4631-992a-d4c71011f4fa', 'f4a09709-6c0c-4db0-bb76-d800ec9458e8', '9e2642e9-1a33-443a-bfbb-1e919c49a853', '31bc179d-d8a1-47ce-bd00-c6473875cedc', '0e81c9fe-5915-4e5a-bac0-1cdc8ed2ab52', '1d8b31ce-ac8d-4237-a4d5-21d82062b54e'], 'embeddings': None, 'documents': [\"Mai Zheng @Iowa State\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMai Zheng\\n               (Mike)\\n\\nAssociate Professor\\nDept.\\n                of Electrical and Computer Engineering\\n\\nData Storage Lab (DSL)\\n\\nCenter for Cybersecurity Innovation\\n                & Outreach (CyIO)\\n\\nCenter for Wireless, Communities and\\n                Innovation (WiCI)\\n\\n \\n Office: 349 Durham Hall\\n              Phone: (515)\\n                294-6285 \\n              Email: mai AT iastate DOT edu \\nwww.ece.iastate.edu/~mai\\n\\n\\n\\n I'm interested in all\\n                  things data storage (e.g., file systems,\\n              non-volatile memories, key-value stores, data-intensive computing,\\n              data-centric infrastructures). I'm leading the Data\\n                  Storage Lab where we play with the latest storage\\n              technologies and strive to advance the integrity, security,\\n              scalability, usability etc for data, for people, or just for fun.\", \"Data Storage Lab\\nOur research are\\n              motivated by real problems of mission-critical systems that jeopardize\\n              data, e.g.: \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n                              Crash, \\n                              Corruption, & Bug\\n                          across system layers\\n                          ==> [SSD: TOCS'16/FAST'13 |\\n                       \\n                        FS: FAST'23,\\n                        FAST'18 |\\n                          OS: TOS'23 |\\n                        DB: OSDI'14]\\n                         Data\\n                              Lost & Service\\n                              Disruption\\n                          @HPC/Data\\n                            centers at scale\", \"==> [HotStorage'24,\\n                        TOS'22/ICS'18,\\n                          IPDPS'23,\\n                        ATC'19]\\n                        Data\\n                              Provenance, Observability,\\n                          & Scalability\\n                          challenges\\n                        ==> [TPDS'24/HPDC'22,\\n                        ASPLOS'23,\\n                          ARA Platform]\\n                      \\n\\n\\n\\n\\n\\nWe build\\n              systems/tools to attack such problems and open source our \\n                research prototypes/datasets. \\n\\n\\n\\n\\n Current Members \\n\\n\\n\\nFaculty: Mai\\n                        Zheng \\nStudents:\\n                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWei Xu\\nChao Shi\\nRoop Kiran\\nAhmed Dajani\\nVarun Girimaji\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nVidhya Mannathu Parambil \\nJoshua John\\n Aaron Trelstad  \\n Zeren Yang\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Selected Projects\\n\\n\\n\\nLarge-Scale\\n                    High-Performance Storage Systems\", \"Large-scale distributed storage\\n                            systems   are critical infrastructures typically deployed in data centers and high-perfomrance computing (HPC) centers to \\n                            empower data-intensive computations and \\n                            data-driven discoveries (e.g., AI/ML applications). Unfortunately,\\n                             due to the complexity and scale, even state-of-the-art systems may experience correctness\\n                            and/or performance issues. \\n                            We are building frameworks to improve data storage at scale\\n                             for robust and high-performant data-driven discoveries.\\nRelevant Papers:\\n                            [IPDPS'25\\n                            | CN'25\\n                            | HotStorage'24\\n                            | ASPLOS'23\\n                            | IPDPS'23a\\n                            | IPDPS'23b\\n                            | TOS'22\", \"| ASPLOS'23\\n                            | IPDPS'23a\\n                            | IPDPS'23b\\n                            | TOS'22\\n                             | HPDC'22\\n                            | HotStorage'21\\n                            (video)\\n                            | PDSW'20\\n                            (slides)\\n                            | \\n                                  USENIX ATC'19 (slides)\\n                            | MSST'19\\n                                  | PDSW'18\\n                                (slides)\\n                            | ICS'18\\n                            (slides)\\n                            \\n                            | PDSW'16\\n                            (slides)]\\n                            \\nOpen Source\\n                                Artifacts: [PFault | ARA Platform]\", 'Main Sponsors: \\n                                [NSF \\n                                | Samsung\\n                                | NIFA \\n                                | US Ignite]\\n                              \\n\\n\\n\\n\\n\\n\\n\\n Single-Machine Storage', \"Local storage systems running on a single machine serve as the\\n                                cornerstone of many large-scale systems and applications. Unfortunately, despite decades of\\n                                evolution and various protections, the classic local storage\\n                                systems may still run into issues in practice\\n                                (e.g., data corruptions, metadata\\n                                inconsistencies). What's worse, the same issues\\n                                that occur to lcoal storage systems may also affect their\\n                                maintenance/recovery utilities and/or\\n                                other applications using them, leading to\\n                                cascading problems. We are investigating the fundamental\\n                                problems and developing mitigation solutions.\\nRelevant Papers:\\n                                [TOCS'25\", \"problems and developing mitigation solutions.\\nRelevant Papers:\\n                                [TOCS'25\\n                                  | FAST'23\\n                                | HotStorage'22\\n                                (slides)\\n                                | FAST'22-WiP\\n                                (video)\\n                                | TOS'18\\n                                | FAST'18\\n                                (slides)\\n                                | HotStorage'17\\n                                (slides)\\n                                | FAST'17-WiP]\", 'Open Source\\n                                    Artifacts: [ConfD | RFSCK]\\n                              \\n Main Sponsors: \\n                                [NSF \\n                                | Western Digital]\\n                              \\n\\n\\n\\n\\n\\n\\n\\n\\n  Cross-Layer\\n                        Issues on Data Path', \"The storage  stack contains a deep data I/O path involving complicated layers (e.g., solid-state drives (SSD), persistent memories (PM), device drivers, local and parallel\\n                                file systems, databases, blockchain storage with cloud backends). Besides\\n                                latent issues in individual layers, many\\n                                desired properties may be violated due to  cross-layer dependencies, hurting the\\n                                end-to-end gurantees and data integrity. We take a holistic\\n                                view to investigate such daunting challenges across system layers. \\nRelevant Papers:\\n                                [IPDPS'25\\n                                 | TOS'23\\n                                | FAST'23\\n                                | Dagstuhl'22\\n                                | TOS'22\\n                                | NVMW'23\\n                                | TC'22\", \"| Dagstuhl'22\\n                                | TOS'22\\n                                | NVMW'23\\n                                | TC'22\\n                                | SYSTOR'21\\n                                (video)\\n                                | FAST'20-WiP\\n                                | \\n                                  ATC'19\\n                                | TOS'18\\n                                | TOCS'16\\n                                | OSDI'14\\n                                (slides)\\n                                | FAST'13\\n                                (slides)\\n                                ]\\nOpen Source\\n                                    Artifacts: [BugBenchk \\n                                | ConfD | PFault]\\n Main Sponsors: \\n                                [NSF \\n                                | Western Digital]\", 'Data Provenance &\\n                        Observability', \"Understanding the origin and quality of data\\n                                (e.g., the root cause of an anomaly, the\\n                                reproducibility of the best result) becomes more\\n                                and more challenging due to the ever-increasing\\n                                data volume and system complexity. Data\\n                                  provenance, or data lineage, describes the\\n                                life cycle of data, which is essential to\\n                                address the challenge. We are building\\n                                frameworks to capture rich metadata and generate\\n                                provenance to ensure the observability,\\n                                reproducibility, explainability, auditability,\\n                                trustworthiness, etc of systems and data.\\nRelevant Papers:\\n                                [TPDS'24\\n                                | HPDC'22\", \"trustworthiness, etc of systems and data.\\nRelevant Papers:\\n                                [TPDS'24\\n                                | HPDC'22\\n                                | NAS'22\\n                                | FAST'22-WiP\\n                                | DOE-ASRC-Data'22\\n                                | TBench'21\\n                                (video)\\n                                | HotStorage'20\\n                                (slides)\\n                                ]\\nOpen Source Artifacts: \\n                                [PROV-IO\\n                                | BugBenchk]\\n                              \\nMain Sponsors: \\n                                [NSF \\n                                | LBNL \\n                                | Samsung]\", 'Data Infrastructure for\\n                        Rural America', \"ARA is a data infrastructure for\\n                                advanced wireless research being deployed across\\n                                the ISU campus, City of Ames, and surrounding\\n                                research and producer farms as well as rural\\n                                communities in central Iowa, spanning a rural\\n                                area with diameter over 60km. It serves as a\\n                                wireless living lab for smart and connected\\n                                rural communities and rich experimental data,\\n                                enabling the research and development of\\n                                rural-focused wireless technologies that provide\\n                                affordable, high-capacity connectivity to rural\\n                                communities and industries such as agriculture.\\n                              \\nRelevant Papers:\\n                                [ CN'25\", \"communities and industries such as agriculture.\\n                              \\nRelevant Papers:\\n                                [ CN'25\\n                                | MobiCom'23\\n                                | WiNTECH'22\\n                                | \\n                                  WiNTECH'21]\", 'Open Source\\n                                Artifacts: [ARA Platform]\\n                              \\n\\n                                Main Sponsors: \\n                                [NSF \\n                                | NIFA \\n                                | US Ignite\\n                                | PAWR Industry Consortium]\\n                              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Selected Outreach Activities \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Full\\n                    Publication List  \\n\\n Alumni\\n \\n\\n Acknowledgements\\n                       \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n\\n\\n Homepage\\n\\n                  CV \\n Data\\n                  Storage Lab\\n\\n                  Publications\\n\\n                  Students\\n\\n                  Teaching\\n\\n                  Service \\n\\n                  Ack.'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [{'title': 'Mai Zheng @Iowa State', 'language': 'No language found.', 'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html'}, {'language': 'No language found.', 'title': 'Mai Zheng @Iowa State', 'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html'}, {'language': 'No language found.', 'title': 'Mai Zheng @Iowa State', 'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html'}, {'language': 'No language found.', 'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'title': 'Mai Zheng @Iowa State'}, {'language': 'No language found.', 'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'title': 'Mai Zheng @Iowa State'}, {'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'title': 'Mai Zheng @Iowa State', 'language': 'No language found.'}, {'title': 'Mai Zheng @Iowa State', 'language': 'No language found.', 'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html'}, {'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'language': 'No language found.', 'title': 'Mai Zheng @Iowa State'}, {'title': 'Mai Zheng @Iowa State', 'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'language': 'No language found.'}, {'language': 'No language found.', 'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'title': 'Mai Zheng @Iowa State'}, {'title': 'Mai Zheng @Iowa State', 'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'language': 'No language found.'}, {'title': 'Mai Zheng @Iowa State', 'language': 'No language found.', 'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html'}, {'language': 'No language found.', 'title': 'Mai Zheng @Iowa State', 'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html'}, {'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'title': 'Mai Zheng @Iowa State', 'language': 'No language found.'}, {'language': 'No language found.', 'title': 'Mai Zheng @Iowa State', 'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html'}, {'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'language': 'No language found.', 'title': 'Mai Zheng @Iowa State'}, {'title': 'Mai Zheng @Iowa State', 'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'language': 'No language found.'}, {'title': 'Mai Zheng @Iowa State', 'source': 'https://www.ece.iastate.edu/~mai/lab/dsl.html', 'language': 'No language found.'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCollection 1 - \", vectorstore._collection.get(ids=['38244db0-385e-4fde-bfb7-f8c29314427b'], include=[\"embeddings\", \"documents\"]))\n",
        "print(\"\\nCollection 2 - \", vectorstore._collection.get(ids=['f38503fc-d438-4fd9-b5f1-abed96049c83'], include=[\"embeddings\", \"documents\"]))\n",
        "print(\"\\nCollection 3 - \", vectorstore._collection.get(ids=['13ac6a63-1a70-46bc-9333-e278b66b9040'], include=[\"embeddings\", \"documents\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAuSljxw80XV",
        "outputId": "c2e8d2b2-34a0-4e4f-ab68-eb3fab86720e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collection 1 -  {'ids': ['38244db0-385e-4fde-bfb7-f8c29314427b'], 'embeddings': array([[-0.02756152, -0.00676674,  0.00685028, ..., -0.0282833 ,\n",
            "        -0.00510262, -0.01322605]]), 'documents': [\"Mai Zheng @Iowa State\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMai Zheng\\n               (Mike)\\n\\nAssociate Professor\\nDept.\\n                of Electrical and Computer Engineering\\n\\nData Storage Lab (DSL)\\n\\nCenter for Cybersecurity Innovation\\n                & Outreach (CyIO)\\n\\nCenter for Wireless, Communities and\\n                Innovation (WiCI)\\n\\n \\n Office: 349 Durham Hall\\n              Phone: (515)\\n                294-6285 \\n              Email: mai AT iastate DOT edu \\nwww.ece.iastate.edu/~mai\\n\\n\\n\\n I'm interested in all\\n                  things data storage (e.g., file systems,\\n              non-volatile memories, key-value stores, data-intensive computing,\\n              data-centric infrastructures). I'm leading the Data\\n                  Storage Lab where we play with the latest storage\\n              technologies and strive to advance the integrity, security,\\n              scalability, usability etc for data, for people, or just for fun.\"], 'uris': None, 'included': ['embeddings', 'documents'], 'data': None, 'metadatas': None}\n",
            "\n",
            "Collection 2 -  {'ids': ['f38503fc-d438-4fd9-b5f1-abed96049c83'], 'embeddings': array([[-0.00045822,  0.00736604,  0.01645957, ...,  0.00263443,\n",
            "        -0.02827564, -0.01534016]]), 'documents': [\"Data Storage Lab\\nOur research are\\n              motivated by real problems of mission-critical systems that jeopardize\\n              data, e.g.: \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n                              Crash, \\n                              Corruption, & Bug\\n                          across system layers\\n                          ==> [SSD: TOCS'16/FAST'13 |\\n                       \\n                        FS: FAST'23,\\n                        FAST'18 |\\n                          OS: TOS'23 |\\n                        DB: OSDI'14]\\n                         Data\\n                              Lost & Service\\n                              Disruption\\n                          @HPC/Data\\n                            centers at scale\"], 'uris': None, 'included': ['embeddings', 'documents'], 'data': None, 'metadatas': None}\n",
            "\n",
            "Collection 3 -  {'ids': ['13ac6a63-1a70-46bc-9333-e278b66b9040'], 'embeddings': array([[ 0.00962926, -0.01597894,  0.02024095, ..., -0.0029491 ,\n",
            "        -0.02250921, -0.01499651]]), 'documents': [\"==> [HotStorage'24,\\n                        TOS'22/ICS'18,\\n                          IPDPS'23,\\n                        ATC'19]\\n                        Data\\n                              Provenance, Observability,\\n                          & Scalability\\n                          challenges\\n                        ==> [TPDS'24/HPDC'22,\\n                        ASPLOS'23,\\n                          ARA Platform]\\n                      \\n\\n\\n\\n\\n\\nWe build\\n              systems/tools to attack such problems and open source our \\n                research prototypes/datasets. \\n\\n\\n\\n\\n Current Members \\n\\n\\n\\nFaculty: Mai\\n                        Zheng \\nStudents:\\n                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWei Xu\\nChao Shi\\nRoop Kiran\\nAhmed Dajani\\nVarun Girimaji\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nVidhya Mannathu Parambil \\nJoshua John\\n Aaron Trelstad  \\n Zeren Yang\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Selected Projects\\n\\n\\n\\nLarge-Scale\\n                    High-Performance Storage Systems\"], 'uris': None, 'included': ['embeddings', 'documents'], 'data': None, 'metadatas': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Set the vectorstore as the retriever\n",
        "2. I tried the Rag prompt available in the Langchain hub (Can also create a prompt if needed)\n",
        "3. Send this prompt to LLM, create a chatmodel\n",
        "\n"
      ],
      "metadata": {
        "id": "X24Pkd2DtXhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "EWUD5kc29gdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")"
      ],
      "metadata": {
        "id": "w861xJ0vCMPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI()"
      ],
      "metadata": {
        "id": "XVI5dUlZCtFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Whenever you need the question as it is - we use runnable(task) passthrough in langchain.\n",
        "2. Whatever context im getting i need to join them and combine them together (join the splits in the vector store)\n",
        "3. Create a pipeline with the input as context and question\n",
        "passing these to the prompt\n",
        "-pass these to the llm\n",
        "- use stroutputparser to parse the output as content"
      ],
      "metadata": {
        "id": "BZMI2A0Vt7WH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "f5knpKvnDqMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "  return \"\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "R3wYXpfeEFP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = ({\"context\" : retriever | format_docs, \"question\" : RunnablePassthrough()}\n",
        "             | prompt\n",
        "             | llm\n",
        "             | StrOutputParser())"
      ],
      "metadata": {
        "id": "V5np_Tc_DFXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"Is Roop in data storage lab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "utTbRPaAKWEz",
        "outputId": "93747d85-55bb-45b6-ea01-c99b5111fa0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Roop Kiran is in the Data Storage Lab led by Mai Zheng, an associate professor in the Department of Electrical and Computer Engineering at Iowa State University. The lab focuses on advancing the integrity, security, scalability, and usability of data storage technologies. Roop Kiran is one of the students involved in the lab's research projects.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"Was Aadddron Trelstad an Undergraduate Intern?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "2mfkgqM4KakE",
        "outputId": "8a7c851e-1b16-4122-9305-e7f38b1d2d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't have enough information to confirm if Aadddron Trelstad was an Undergraduate Intern.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"Who all are the Ph.D. Mentees in the lab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "E8uvOmwXKjfa",
        "outputId": "ba33e937-055f-4149-c501-72819445feff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Ph.D. Mentees in the lab led by Mai Zheng at Iowa State University include Wei Xu, Chao Shi, Roop Kiran, Ahmed Dajani, Varun Girimaji, Vidhya Mannathu Parambil, Joshua John, Aaron Trelstad, and Zeren Yang. The lab focuses on large-scale storage systems and has open-source artifacts like the ARA Platform, with main sponsors including NSF, NIFA, US Ignite, and PAWR Industry Consortium.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"What all projects in this lab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "Bu1u0MSdKvUK",
        "outputId": "6f56b4bc-f1d8-4f29-893a-078e0da99266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The projects in this lab include Large-Scale High-Performance Storage Systems, and Data Provenance & Observability challenges. The lab is motivated by real problems in mission-critical systems that affect data across different layers. Some open-source artifacts from the lab include the ARA Platform.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Checking the exact prompt passed to the llm for this experiment\n",
        "1. Create a custom function using RunnableLamda\n",
        "2. Create a function called print_prompt\n",
        "3. Create the rag chain again with the custom function for printing the prompt as input to llm\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "2CUaK88Lkmq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda"
      ],
      "metadata": {
        "id": "N1k9vBnqLduP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_prompt(prompt_text):\n",
        "  print(\"Prompt - \", prompt_text)\n",
        "  return prompt_text"
      ],
      "metadata": {
        "id": "V6rw1lQCLl8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain_with_print = ({\"context\" : retriever | format_docs, \"question\" : RunnablePassthrough()}\n",
        "             | prompt\n",
        "             | RunnableLambda(print_prompt)\n",
        "             | llm\n",
        "             | StrOutputParser())"
      ],
      "metadata": {
        "id": "J4LDfcGMKzqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain_with_print.invoke(\"What all projects are covered in the lab?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "R-wWOqyjLyWh",
        "outputId": "464f6fd2-40ca-48d7-d86f-50235edc3925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt -  messages=[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: What all projects are covered in the lab? \\nContext: Data Storage Lab\\nOur research are\\n              motivated by real problems of mission-critical systems that jeopardize\\n              data, e.g.: \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n                              Crash, \\n                              Corruption, & Bug\\n                          across system layers\\n                          ==> [SSD: TOCS'16/FAST'13 |\\n                       \\n                        FS: FAST'23,\\n                        FAST'18 |\\n                          OS: TOS'23 |\\n                        DB: OSDI'14]\\n                         Data\\n                              Lost & Service\\n                              Disruption\\n                          @HPC/Data\\n                            centers at scale\\nOpen Source\\n                                Artifacts: [ARA Platform]\\n                              \\n\\n                                Main Sponsors: \\n                                [NSF \\n                                | NIFA \\n                                | US Ignite\\n                                | PAWR Industry Consortium]\\n                              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Selected Outreach Activities \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Full\\n                    Publication List  \\n\\n Alumni\\n \\n\\n Acknowledgements\\n                       \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n\\n\\n Homepage\\n\\n                  CV \\n Data\\n                  Storage Lab\\n\\n                  Publications\\n\\n                  Students\\n\\n                  Teaching\\n\\n                  Service \\n\\n                  Ack.\\ncommunities and industries such as agriculture.\\n                              \\nRelevant Papers:\\n                                [ CN'25\\n                                | MobiCom'23\\n                                | WiNTECH'22\\n                                | \\n                                  WiNTECH'21]\\n==> [HotStorage'24,\\n                        TOS'22/ICS'18,\\n                          IPDPS'23,\\n                        ATC'19]\\n                        Data\\n                              Provenance, Observability,\\n                          & Scalability\\n                          challenges\\n                        ==> [TPDS'24/HPDC'22,\\n                        ASPLOS'23,\\n                          ARA Platform]\\n                      \\n\\n\\n\\n\\n\\nWe build\\n              systems/tools to attack such problems and open source our \\n                research prototypes/datasets. \\n\\n\\n\\n\\n Current Members \\n\\n\\n\\nFaculty: Mai\\n                        Zheng \\nStudents:\\n                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWei Xu\\nChao Shi\\nRoop Kiran\\nAhmed Dajani\\nVarun Girimaji\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nVidhya Mannathu Parambil \\nJoshua John\\n Aaron Trelstad  \\n Zeren Yang\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Selected Projects\\n\\n\\n\\nLarge-Scale\\n                    High-Performance Storage Systems \\nAnswer:\", additional_kwargs={}, response_metadata={})]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The projects covered in the lab include large-scale high-performance storage systems. The research focuses on real-world issues affecting mission-critical systems. The lab also works on data storage challenges related to data provenance, observability, and scalability.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}